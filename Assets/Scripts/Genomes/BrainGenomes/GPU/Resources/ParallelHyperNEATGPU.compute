// Each #kernel tells which function to compile; you can have many kernels
#pragma kernel CSMain
#include "../../../../Brains/GPU/Resources/BrainStructs.cginc"

struct CPPNOutputArray{
    float initial_weight;
    float learning_rate;
    float4 hebb_ABCD_coefficients;
    float bias;
    float sigmoid_alpha;
    float sign;
};

// keep this up to date with HyperNEATBrainGenome.CPPNconnectionParallel
struct CPPNConnection{
    int from_idx;
    float weight;
};

// keep this up to date with HyperNEATBrainGenome.CPPNnodeParallel
struct CPPNNode{
    int function;
    int number_of_inputs;
    int connection_start_idx;
};


int SUBSTRATE_SIZE_X;
int SUBSTRATE_SIZE_Y;
int SUBSTRATE_SIZE_Z;
int NUM_OF_NODES;
int OUTPUT_NODES_START_IDX;
int OUTPUT_NODES_END_IDX;
float CONNECTION_PRUNING_CUTOFF;

// Create a RenderTexture with enableRandomWrite flag and set it
// with cs.SetTexture
RWStructuredBuffer<Neuron> neurons;
RWStructuredBuffer<Synapse> synapses;

RWStructuredBuffer<float> CPPN_nodes_outputs; 
RWStructuredBuffer<CPPNNode> CPPN_nodes; 
RWStructuredBuffer<CPPNConnection> CPPN_connections;


//keep this up to date with the CPPNFunction Enum
#define CPPN_FUNCTION_Linear 0
#define CPPN_FUNCTION_Sigmoid 1
#define CPPN_FUNCTION_Gaussian 2
#define CPPN_FUNCTION_Sine 3
#define CPPN_FUNCTION_Abs 4
#define CPPN_FUNCTION_Step 5
#define CPPN_FUNCTION_ReLU 6

#define CPPN_FUNCTION_Cosine 7
#define CPPN_FUNCTION_Tangent 8
#define CPPN_FUNCTION_HyperTangent 9
#define CPPN_FUNCTION_HyperCosine 10
#define CPPN_FUNCTION_HyperSine 11

#define CPPN_FUNCTION_Cube 12
#define CPPN_FUNCTION_Square 13
#define CPPN_FUNCTION_SquareRoot 14





int Index_FlatFromVector3(int x, int y, int z)
{
    return x + SUBSTRATE_SIZE_X * y + SUBSTRATE_SIZE_X * SUBSTRATE_SIZE_Y * z;
}


int3 Index_int3FromFlat(int i)
{
    int x = i % SUBSTRATE_SIZE_X;
    int y = floor(i / SUBSTRATE_SIZE_X) % SUBSTRATE_SIZE_Y;
    int z = floor(i / (SUBSTRATE_SIZE_X * SUBSTRATE_SIZE_Y));
    return int3(x, y, z);
}

int TOTAL_SUBSTRATE_SIZE()
{
    return SUBSTRATE_SIZE_X * SUBSTRATE_SIZE_Y * SUBSTRATE_SIZE_Z;
}


float EvaluateFunction(int function, float sum){
    if(function == CPPN_FUNCTION_Linear){
        return sum;
    }else if(function == CPPN_FUNCTION_Sigmoid){
        return 1.0 / (1.0 + exp(-1 * sum));
    }else if(function == CPPN_FUNCTION_Gaussian){
        return exp(-(sum * sum));
    }else if(function == CPPN_FUNCTION_Sine){
        return sin(sum);
    }else if(function == CPPN_FUNCTION_Abs){
        return abs(sum);
    }else if(function == CPPN_FUNCTION_Step){
        return sum > 0 ? 1 : 0;
    }else if(function == CPPN_FUNCTION_ReLU){
        return sum > 0 ? sum : 0;
    }else if(function == CPPN_FUNCTION_Cosine){
        return cos(sum);
    }else if(function == CPPN_FUNCTION_Tangent){
        return tan(sum);
    }else if(function == CPPN_FUNCTION_HyperTangent){
        return tanh(sum);
    }else if(function == CPPN_FUNCTION_HyperCosine){
        return cosh(sum);
    }else if(function == CPPN_FUNCTION_HyperSine){
        return sinh(sum);
    }else if(function == CPPN_FUNCTION_Cube){
        return sum * sum * sum;
    }else if(function == CPPN_FUNCTION_Square){
        return sum * sum;
    }else if(function == CPPN_FUNCTION_SquareRoot){
        return sqrt(sum);
    }else{
        return -1;
    }
}

float EvaluateCPPNNode(CPPNNode node, int node_idx_offset){
    float sum = 0;
    for (int i = node.connection_start_idx; i < node.connection_start_idx + node.number_of_inputs; i++)
    {
        CPPNConnection connection = CPPN_connections[i];
        float input_value = CPPN_nodes_outputs[node_idx_offset + connection.from_idx];
        sum += connection.weight * input_value;
    }
    return EvaluateFunction(node.function, sum);
}

CPPNOutputArray EvaluateCPPN(int i, int x1, int y1, int z1, int x2, int y2, int z2){
        CPPNOutputArray output_array;
        output_array.hebb_ABCD_coefficients = float4(0, 0, 0, 0);

        int node_idx_offset = i * NUM_OF_NODES;
        int k;
        float result;

        // do inputs
        for (k = 0; k < OUTPUT_NODES_START_IDX; k++)
        {
            if (k == 0)
            {
                result = 1;
            }
            else if (k == 1)
            {
                result = (((float)x1 / (float)SUBSTRATE_SIZE_X) - 0.5f) * 2; ;
            }
            else if (k == 2)
            {
                result = (((float)y1 / (float)SUBSTRATE_SIZE_Y) - 0.5f) * 2;
            }
            else if (k == 3)
            {
                result = (((float)z1 / (float)SUBSTRATE_SIZE_Z) - 0.5f) * 2;
            }
            else if (k == 4)
            {
                result = (((float)x2 / (float)SUBSTRATE_SIZE_X) - 0.5f) * 2;
            }
            else if (k == 5)
            {
                result = (((float)y2 / (float)SUBSTRATE_SIZE_Y) - 0.5f) * 2;
            }
            else// if (k == 6)
            {
                result = (((float)z2 / (float)SUBSTRATE_SIZE_Z) - 0.5f) * 2;
            }

            CPPN_nodes_outputs[node_idx_offset + k] = result;
        }


 


        // do hidden nodes
        for (k = OUTPUT_NODES_END_IDX; k < NUM_OF_NODES; k++)
        {
            CPPN_nodes_outputs[node_idx_offset + k] = EvaluateCPPNNode(CPPN_nodes[k], node_idx_offset);
        }

        // do outputs
        int m = 0;
        for (k = OUTPUT_NODES_START_IDX; k < OUTPUT_NODES_END_IDX; k++)
        {
            
            result = EvaluateCPPNNode(CPPN_nodes[k], node_idx_offset);
            CPPNNode node = CPPN_nodes[node_idx_offset + k];

            if (m == 0)
            {
                output_array.initial_weight = result;
            }
            else if (m == 1)
            {
                output_array.learning_rate = result;
            }
            else if (m == 2)
            {
                output_array.hebb_ABCD_coefficients[0] = result;
            }
            else if (m == 3)
            {
                output_array.hebb_ABCD_coefficients[1] = result;
            }
            else if (m == 4)
            {
                output_array.hebb_ABCD_coefficients[2] = result;
            }
            else if (m == 5)
            {
                output_array.hebb_ABCD_coefficients[3] = result;
            }
            else if (m == 6)
            {
                output_array.bias = result;
            }
            else if (m == 7)
            {
                output_array.sigmoid_alpha = result;
            } else if (m == 8)
            {
                output_array.sign = result;
            }
            m++;
        }

        return output_array;
}


void Evaluate(int i)
{
    int neuron1_flat_idx = (int)floor(i / TOTAL_SUBSTRATE_SIZE());
    int neuron2_flat_idx = i - neuron1_flat_idx * TOTAL_SUBSTRATE_SIZE();

    int3 neuron1_index = Index_int3FromFlat(neuron1_flat_idx);
    int x1 = neuron1_index.x;
    int y1 = neuron1_index.y;
    int z1 = neuron1_index.z;

    int3 neuron2_index = Index_int3FromFlat(neuron2_flat_idx);
    int x2 = neuron2_index.x;
    int y2 = neuron2_index.y;
    int z2 = neuron2_index.z;


    CPPNOutputArray CPPN_outputs = EvaluateCPPN(i, x2, y2, z2, x1, y1, z1); //from coord2 to coord1
    float initial_weight = CPPN_outputs.initial_weight;
    float learning_rate = CPPN_outputs.learning_rate;

    if (x2 == 0 && y2 == 0 && z2 == 0)
    {
        float bias = CPPN_outputs.bias;
        float sigmoid_alpha = CPPN_outputs.sigmoid_alpha;

        Neuron neuron1 = neurons[neuron1_flat_idx];
        neuron1.type = NEURON_TYPE_PERCEPTRON;
        neuron1.sign = CPPN_outputs.sign;

        neuron1.bias = bias;
        neuron1.sigmoid_alpha = sigmoid_alpha;
            
          
        neuron1.synapse_start_idx = neuron1_flat_idx * TOTAL_SUBSTRATE_SIZE();
        neuron1.synapse_count = TOTAL_SUBSTRATE_SIZE();
        neuron1.position = int3(x1, y1, z1);
        neurons[neuron1_flat_idx] = neuron1;

    }

    if (abs(initial_weight) > CONNECTION_PRUNING_CUTOFF)
    {
        //DevelopmentNeuron neuron2 = substrate[x2, y2, z2];
        Synapse synapse;
        synapse.learning_rate_r = learning_rate;
        synapse.from_neuron_idx = neuron2_flat_idx;
        synapse.coefficient_A = CPPN_outputs.hebb_ABCD_coefficients[0];
        synapse.coefficient_B = CPPN_outputs.hebb_ABCD_coefficients[1];
        synapse.coefficient_C = CPPN_outputs.hebb_ABCD_coefficients[2];
        synapse.coefficient_D = CPPN_outputs.hebb_ABCD_coefficients[3];
        synapse.weight = initial_weight;

        if (z1 == 0)
        {
            // sensory neuron
            synapse.learning_rate_r = 0;
            synapse.weight = 0;
        }

        synapses[i] = synapse;
    }

}

#define NUM_THREADS 64
[numthreads(NUM_THREADS,1,1)]
void CSMain (uint3 id : SV_DispatchThreadID)
{
    Evaluate(id.x);
}
